"""
author: Vansh Pratap Singh
Python application for the generation & retrieval of store reports along
with other features such as db syncing, threading, etc.
"""

import threading

from flask import Flask, jsonify, send_file
from flask_apscheduler import APScheduler

from service import db_service, business_logic

app = Flask(__name__)
scheduler = APScheduler()


def sync_db_every_hour():
    """
    syncs the database with the csvs
    :return: None, only to be used for syncing the database with the csv files
    """
    db_service.sync_complete_store_db()


@app.route('/trigger_report')
def trigger_report():
    """
    API to generate a new report for each store (unique store_ids), consisting of various fields like:
    store_id, uptime_last_week(in hours), downtime_last_week(in hours),
    uptime_last_day(in hours), downtime_last_day(in hours),
    uptime_last_hour(in minutes), downtime_last_hour(in minutes)
    :return: Report id of the report that is being generated by the API
    """
    filename, report_id = business_logic.generate_and_verify_filename()
    business_logic.report_generation_status(report_id, 'RUNNING')
    threading.Thread(target=business_logic.generate_csv_file_and_map_to_db, args=(filename, report_id)).start()
    return jsonify({'report_id': report_id})


@app.route('/get_report/<report_id>', methods=['GET'])
def get_report(report_id):
    """
    API to get the report (in csv format) for the requested report_id.
    Returns an appropriate message if the file is not found (no report exists for the given report_id)
    or if the report generation of the given report_id is still in progress, else if the report has already
    been generated for the given report_id, it will simply return the report as a CSV.
    :param report_id: report id of the report which has to be fetched
    :return: CSV file or a message, depending on if the file has been generated for the given report_id or not.
    """
    file_location = business_logic.find_csv_file_by_report_id(report_id)
    if file_location is None:
        return jsonify({'message': 'File not found'})
    else:
        if file_location == 'INVALID':
            return jsonify({'message': 'Check the report id again. No report exists with the given report id!'})
        if file_location == "RUNNING":
            return jsonify({'message': 'Running! Report Generation is still in progress. Hit the API after a few '
                                       'seconds.'})
        return send_file(file_location, as_attachment=True, download_name=f"report_{report_id}.csv")


if __name__ == '__main__':
    """
    [IF RUNNING FOR THE FIRST TIME] -> UNCOMMENT THE CODE LINE [sync_db_every_hour()] BELOW & RUN THE FILE. 
    DOING SO WILL SYNC THE LOCAL DATABASE WITH THE CSV FILES.
    AFTER THAT, YOU CAN COMMENT THE LINE AGAIN AND RUN THE APPLICATION. 
    ALSO CHANGE THE CREDENTIALS FOR THE DATABASE WHICH CAN BE FOUND IN THE get_db_credentials() METHOD 
    OF THE db_service MODULE. DOING SO WILL ENSURE THAT THE APPLICATION IS ABLE TO ESTABLISH A CONNECTION 
    WITH THE DESIRED DATABASE.
    """
    # sync_db_every_hour()
    db_sync_time_in_seconds = 3600
    # as specified in the problem statement, the csv files will be updated on an hourly basis, so we sync the db on an hourly basis as well
    scheduler.add_job(id='Scheduled Task', func=sync_db_every_hour, trigger="interval", seconds=db_sync_time_in_seconds)
    scheduler.start()
    app.run(host="0.0.0.0", port=8080)
